# Web Scraping with Python

В репозитории представлены практические примеры сбора и извлечения структурированных данных из веб-источников с использованием Python.

Код организован по типам источников и уровню сложности и отражает реальные сценарии работы с веб-данными: от статических HTML-страниц до динамического контента, API и механизмов защиты от автоматизированных запросов. Основной акцент сделан на чистую архитектуру, переиспользуемые компоненты и устойчивость решений.

## Структура репозитория

### `static_pages/`
Примеры извлечения данных из статических HTML-страниц, где контент доступен в ответе сервера без выполнения JavaScript.

Типовые задачи:
- анализ структуры HTML-документа
- работа с CSS-селекторами и XPath
- обработка пагинации
- извлечение и первичная обработка данных

---

### `dynamic_pages/`
Примеры сбора данных со страниц, где контент формируется на стороне клиента с использованием JavaScript.

Рассматриваемые сценарии:
- загрузка данных через XHR / Fetch
- извлечение данных из сетевых запросов
- работа с динамически обновляемым DOM
- использование браузерной автоматизации при необходимости

---

### `api_sources/`
Сбор данных из API, используемых веб- и мобильными приложениями.

Покрываемые темы:
- взаимодействие с REST API
- обработка JSON-ответов
- работа с заголовками и токенами авторизации
- пагинация и ограничения по частоте запросов

---

### `anti_bot/`
Подходы к работе с типовыми механизмами защиты от автоматизированного сбора данных.

Включает:
- настройку HTTP-заголовков и User-Agent
- работу с cookies
- управление задержками между запросами
- использование прокси

---

### `data_export/`
Примеры подготовки и экспорта собранных данных в форматы, удобные для дальнейшего анализа и использования.

Поддерживаемые форматы:
- CSV
- JSON
- структуры, совместимые с Excel

Основной фокус — нормализация данных и практическая применимость результата.

---

### `utils/`
Вспомогательные модули, используемые в разных сценариях сбора данных.

Содержит:
- конфигурацию заголовков
- управление прокси
- логику повторных запросов
- вспомогательные функции и логирование

---

## Используемые технологии
- Python
- requests
- BeautifulSoup
- aiohttp
- Selenium / Playwright (при необходимости)

## Примечание
Все примеры приведены в демонстрационных целях. Репозиторий не связан с какими-либо конкретными веб-ресурсами и не предназначен для нарушения правил использования сайтов.
